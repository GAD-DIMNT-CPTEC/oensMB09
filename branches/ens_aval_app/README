Sistema de Avaliação do SPCON global do CPTEC/INPE

Os programa incluídos neste diretório são as versões iniciais do que virá a ser o "Sistema de Avaliação do SPCON global do CPTEC/INPE". Este sistema torna-se neessário, pois as avaliações feitas para a validação do SPCON a cada nova versão, são frequentemente baseadas em apenas uma ou duas métricas e não necessariamente estão alinhadas com as diretrizes da WMO para a avaliação de modelos, sobretudo, de sistemas de previsão por conjunto. O desenvolvimento deste sistema, além de permitir que várias outras métricas e formas de avaliação sejam inseridas, permitirá que uma revisão mais detalhada da forma de avaliação vigente seja realizada.

Para o desenvolvimento deste sistema, foi escolhida a linguagem de programação Python, devido à sua exponencial expansão e facilidade de manipulação dos dados. Os scripts apresentados nesta versão "zero", são baseados em dois pacotes principais, que facilitam enormenete a manipulação da grande quantidade de arquivos de previsão envolvidos nas avaliações: xarray, dask. O xarray é um pacote que permite criar estruturas de dados georeferenciados em n dimensões. O dask é um pacote que permite a aceleração do processamente dos dados, estando este intrinsecamente relacionado com o xarray. Para o uso dos scripts, todos os arquivos grib do SPCON são antes convertidos para o formato NetCDF, tendo todos os seus metadados apropriadamente anotados. Dessa forma, dimunui-se de forma substancial a quantidade de arquivos a ser tratada pelos scripts. Por exemplo, considerando uma realização típica do SPCON global uma data qualquer, tem-se: 15 análises x 60 previsões (15 dias de previsões a cada 6 horas) = 900 arquivos grib. Contabilizando os arquivos idx e ctl, tem-se ao todo 2.700 arquivos a serem manipuladas para apenas uma única data. Se uma avaliação de 3 meses for realizada (como por exemplo é feito com a avaliação do CRPS), tem-se, portanto: 2.700 arquivos x 30 dias x 2 horários (00 e 12Z) x 3 meses = 486.000 arquivos a serem manipulados. Emcapsulando-se todos os 2.700 arquivos de cada data de realização do SPCON, este valor cai para apenas 180 arquivos. 

Apesar de parecer ser uma solução inteligente para manipulação dos arquivos, à medida que a resolução do modelo e a quantidade de variáveis aumentar, o tamanho dos arquivos NetCDF também aumenta e, consequentemente, a quantidade de memória RAM necessária para o processamento dos dados também aumenta. É neste ponto em que o pacote dask entra em ação. Com ele, é possível fazer cálculos com uma quantidade muito grande de arquivos, mesmo sem se ter a quantidade de memória disponível. Isso se dá porque devido à forma como os objetos e arrays são carregados na memória. Estes elementos são carregados de forma "lazy", que no âmbito da linguagem Python, significa que apenas uma espécie de ponteiro é carregada na memória, e não necessariamente todo o seu conteúdo. Dessa forma, o pacote dask é capaz de criar uma lista de objetos que serão processados em paralelo e de acordo com a quantidade de recursos disponíveis na máquina. Na versão inicial dos scripts, apenas uma pequena porção das ações realizadas são feitas utilizando-se o pacote dask. Para as futuras versão, tem-se por intenção fazer uso extensivo do dask.

Para facilitar o entendimento da lógica utilizada nos scripts, alguns notebooks do Jupyter deverão ser disponibilizados para que as pessoas interessadas em desenvolver o "Sistema de Avaliação do SPCON global do CPTEC/INPE" possam aprender a usar os pacotes xarray e dask dentro do escopo deste projeto.

Última atualização: carlos.bastarz@inpe.br (03/04/2019)
